{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Prototype notebook to semantically represent Learning Path with Schema.org\n",
    "\n",
    "authors: Phil Reed, Alban Gaignard, Leyla Jael Castro\n",
    "\n",
    "- Initially drafted the 20th of November 2025, as part of Bioschemas activities and ELIXIR BioHackathon Europe 2025.\n",
    "- Refined at de.NBI BioHackathon Germany 2025.\n",
    "- To be revised by the community.\n",
    "\n",
    "Any questions, please contact phil.reed@manchester.ac.uk, alban.gaignard@univ-nantes.fr\n",
    "\n"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "!pip install rdflib"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Sample Learning path\n",
    "https://tess.elixir-europe.org/learning_paths/introduction-to-galaxy-and-sequence-analysis-6384c0ed-3546-41cf-ac30-bff8680dd96c\n",
    "\n",
    "LP structure: \n",
    "\n",
    "**Introduction to Galaxy and Sequence analysis** [syllabusSections=M1,M2]\n",
    "- **Module 1: Introduction to Galaxy** [itemListElement=11,12] [nextItem=M2]\n",
    "  - (1.1) A short introduction to Galaxy [nextItem=12]\n",
    "  - (1.2) Galaxy Basics for genomics [nextItem=21]\n",
    "- **Module 2: Basics of Genome Sequence Analysis** [itemListElement=21,22,23,24]\n",
    "  - (2.1) Quality Control [nextItem=22]\n",
    "  - (2.2) Mapping [nextItem=23]\n",
    "  - (2.3) An Introduction to Genome Assembly [nextItem=24]\n",
    "  - (2.4) Chloroplast genome assembly \n",
    "\n"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from rdflib import Graph\n",
    "\n",
    "my_learning_path = \"\"\"\n",
    "@prefix rdf: <http://www.w3.org/1999/02/22-rdf-syntax-ns#> .\n",
    "@prefix owl: <http://www.w3.org/2002/07/owl#> .\n",
    "@prefix rdfs: <http://www.w3.org/2000/01/rdf-schema#> .\n",
    "@prefix schema: <https://schema.org/> .\n",
    "@prefix dct: <http://purl.org/dc/terms/> .\n",
    "@prefix ex: <http://example.org/> .\n",
    "ex:GA_learning_path a schema:Course ;\n",
    "    dct:conformsTo <https://bioschemas.org/profiles/LearningPath> ;\n",
    "    schema:name \"Introduction to Galaxy and Sequence analysis\" ;\n",
    "    schema:description \"This learning path aims to teach you the basics of Galaxy and analysis of sequencing data. \" ;\n",
    "    schema:provider ex:ExampleUniversity ;\n",
    "    schema:courseCode \"GSA101\" ;\n",
    "    schema:syllabusSections ex:Module_2, ex:Module_1 .\n",
    "\t\n",
    "ex:Module_1 a schema:Syllabus, schema:ListItem, schema:ItemList ;  \n",
    "    dct:conformsTo <https://bioschemas.org/profiles/LearningPathModule> ;\n",
    "    schema:name \"Module 1: Introduction to Galaxy\" ;\n",
    "    schema:teaches \"Learn how to create a workflow\" ;\n",
    "    schema:nextItem ex:Module_2 ;\n",
    "    schema:itemListElement ex:TM11, ex:TM12 .\n",
    "ex:TM11 a schema:LearningResource, schema:ListItem ;\n",
    "    dct:conformsTo <https://bioschemas.org/profiles/TrainingMaterial> ;\n",
    "    schema:name \"(1.1) A short introduction to Galaxy\" ;\n",
    "    schema:description \"What is Galaxy\" ;\n",
    "    schema:url \"https://tess.elixir-europe.org/materials/hands-on-for-a-short-introduction-to-galaxy-tutorial?lp=1%3A1\" ;\n",
    "    schema:nextItem ex:TM12 .\n",
    "ex:TM12 a schema:LearningResource, schema:ListItem ;\n",
    "    dct:conformsTo <https://bioschemas.org/profiles/TrainingMaterial> ;\n",
    "    schema:name \"(1.2) Galaxy Basics for genomics\" ;\n",
    "    schema:description \"The basic details for Galaxy genomics\" ;\n",
    "    schema:nextItem ex:TM21 .\n",
    "\n",
    "ex:Module_2 a schema:Syllabus, schema:ListItem, schema:ItemList  ;\n",
    "    dct:conformsTo <https://bioschemas.org/profiles/LearningPathModule> ;\n",
    "    schema:name \"Module 2: Basics of Genome Sequence Analysis\" ;\n",
    "    schema:teaches \"Use genome browser to understand your data\" ;\n",
    "    schema:itemListElement ex:TM21, ex:TM22, ex:TM23, ex:TM24 .\n",
    "ex:TM21 a schema:LearningResource, schema:ListItem ;\n",
    "    dct:conformsTo <https://bioschemas.org/profiles/TrainingMaterial> ;\n",
    "    schema:name \"(2.1) Quality Control\" ;\n",
    "    schema:description \"Ensure you follow quality control practices\" ;\n",
    "    schema:nextItem ex:TM22 .\n",
    "ex:TM22 a schema:LearningResource, schema:ListItem ;\n",
    "    dct:conformsTo <https://bioschemas.org/profiles/TrainingMaterial> ;\n",
    "    schema:name \"(2.2) Mapping\" ;\n",
    "    schema:description \"Alignment and mapping\" ;\n",
    "    schema:nextItem ex:TM23 .\n",
    "ex:TM23 a schema:LearningResource, schema:ListItem ;\n",
    "    dct:conformsTo <https://bioschemas.org/profiles/TrainingMaterial> ;\n",
    "    schema:name \"(2.3) An Introduction to Genome Assembly\" ;\n",
    "    schema:description \"Description of TrainingMaterial 23\" ;\n",
    "    schema:nextItem ex:TM24 .\n",
    "ex:TM24 a schema:LearningResource, schema:ListItem ;\n",
    "    dct:conformsTo <https://bioschemas.org/profiles/TrainingMaterial> ;\n",
    "    schema:name \"(2.4) Chloroplast genome assembly\" ;\n",
    "    schema:description \"Description of TrainingMaterial 24\"  .\n",
    "\"\"\"\n",
    "\n",
    "kg = Graph()\n",
    "kg.parse(data=my_learning_path, format=\"turtle\")\n",
    "kg.serialize(destination=\"lp1.ttl\", format=\"turtle\")\n",
    "kg.serialize(destination=\"lp1.jsonld\", format=\"json-ld\")"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "print(kg.serialize(format=\"turtle\"))\n",
    "print(len(kg))"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "print(kg.serialize(format=\"json-ld\"))"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# I'm interested in a specific training material, what should be the prerequisites ?\n",
    "\n",
    "tm_of_interest = \"(2.3) An Introduction to Genome Assembly\"\n",
    "\n",
    "def query_learning_path():\n",
    "  query = f\"\"\"\n",
    "  SELECT * WHERE {{\n",
    "    ?s schema:name \"{tm_of_interest}\" .\n",
    "    ?prereq schema:nextItem+ ?s .\n",
    "    ?prereq schema:name ?prereq_name .\n",
    "    ?a_module schema:itemListElement ?prereq .\n",
    "    ?a_module schema:name ?module_name .\n",
    "  }}\n",
    "  \"\"\"\n",
    "  # Run SPARQL query\n",
    "  res_kg = kg.query(query)\n",
    "  print(f'If you are interested in {tm_of_interest}')\n",
    "  for r in res_kg:\n",
    "    print(f'You need to perform {r[\"prereq_name\"]} as part of the module {r[\"module_name\"]}')\n",
    "  return res_kg\n",
    "\n",
    "query_learning_path()"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## What we did until now\n",
    "\n",
    "1.  **RDF Graph Initialization**: We loaded a learning path described in Turtle format into an RDFLib graph (`kg`). We extensively used Schema.org to model the LearningPath Syllabus, ItemList and ListItem types, as well as Course and LearningResource types.\n",
    "2.  **Prerequisite Query**: We demonstrated how to query the graph using SPARQL to find prerequisites for a specific learning material.\n"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Visualization of the Schema.org metadata"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from rdflib import Graph, Literal, URIRef\n",
    "from rdflib.namespace import RDF, RDFS, OWL, XSD\n",
    "\n",
    "def extract_relationships_and_names(graph):\n",
    "    # Define prefixes\n",
    "    schema = URIRef(\"https://schema.org/\")\n",
    "    ex = URIRef(\"http://example.org/\")\n",
    "\n",
    "    # 1. Query for all entities with a schema:name and store their names\n",
    "    entity_names = {}\n",
    "    name_query = \"\"\"\n",
    "    PREFIX schema: <https://schema.org/>\n",
    "    SELECT ?entity ?name\n",
    "    WHERE {\n",
    "        ?entity schema:name ?name .\n",
    "    }\n",
    "    \"\"\"\n",
    "    for row in graph.query(name_query):\n",
    "        entity_names[str(row.entity)] = str(row.name)\n",
    "\n",
    "    print(\"Extracted entity names:\")\n",
    "    for uri, name in entity_names.items():\n",
    "        print(f\"  {uri}: {name}\")\n",
    "\n",
    "    # 2. Query for sequential relationships\n",
    "    relationships_query = \"\"\"\n",
    "    PREFIX schema: <https://schema.org/>\n",
    "    SELECT ?s ?p ?o\n",
    "    WHERE {\n",
    "        ?s ?p ?o .\n",
    "        FILTER (?p = schema:nextItem || ?p = schema:itemListElement || ?p = schema:step)\n",
    "    }\n",
    "    \"\"\"\n",
    "    raw_relationships = []\n",
    "    for row in graph.query(relationships_query):\n",
    "        raw_relationships.append((str(row.s), str(row.p), str(row.o)))\n",
    "\n",
    "    print(\"\\nExtracted raw relationships:\")\n",
    "    for rel in raw_relationships:\n",
    "        print(f\"  {rel[0]} -- {rel[1]} --> {rel[2]}\")\n",
    "\n",
    "    # 3. Transform relationships to use names\n",
    "    mermaid_edges = []\n",
    "    for s_uri, p_uri, o_uri in raw_relationships:\n",
    "        s_name = entity_names.get(s_uri, s_uri.split('/')[-1]) # Use URI fragment if name not found\n",
    "        o_name = entity_names.get(o_uri, o_uri.split('/')[-1]) # Use URI fragment if name not found\n",
    "        predicate_type = p_uri.split('/')[-1] # Get predicate name (e.g., nextItem)\n",
    "        mermaid_edges.append((s_name, predicate_type, o_name))\n",
    "\n",
    "    print(\"\\nTransformed relationships for Mermaid diagram:\")\n",
    "    for edge in mermaid_edges:\n",
    "        print(f\"  {edge[0]} -- {edge[1]} --> {edge[2]}\")\n",
    "\n",
    "    return entity_names, mermaid_edges\n",
    "\n",
    "# Call the function with the existing kg graph\n",
    "all_entity_names, all_mermaid_edges = extract_relationships_and_names(kg)\n",
    "\n",
    "# Assign to the global query_learning_path function as well if needed later\n",
    "def query_learning_path():\n",
    "    return all_entity_names, all_mermaid_edges\n",
    "\n",
    "print(\"Relationship extraction complete. Results stored in all_entity_names and all_mermaid_edges.\")"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "mermaid_lines = []\n",
    "mermaid_lines.append('graph TD')\n",
    "\n",
    "for s_name, p_type, o_name in all_mermaid_edges:\n",
    "    # Sanitize names for Mermaid if they contain special characters or spaces\n",
    "    # Mermaid node IDs cannot contain spaces or special characters directly\n",
    "    # We'll use a simple approach: if a name has spaces, enclose it in quotes.\n",
    "    # For simplicity, we'll map original names to safe IDs and use names for labels\n",
    "\n",
    "    # Create a unique ID for each node if it's not already in the entity_names (which are already unique names)\n",
    "    # For this exercise, we will assume the names are unique enough for node IDs or simply use them as both ID and label.\n",
    "    # Mermaid allows IDs with spaces if quoted, but it's cleaner to have simple IDs.\n",
    "    # However, given the prompt directly asks for f'{source_name} -- {predicate_type} --> {target_name}',\n",
    "    # we will use the names as they are, and Mermaid should handle simple spaces correctly in labels.\n",
    "\n",
    "    # Let's ensure node labels are quoted if they contain spaces to be robust\n",
    "    # Mermaid syntax: A[\"Node Name\"] or A --> B[\"Another Node\"]\n",
    "    # For simplicity, let's use the names directly as node IDs and labels.\n",
    "    # Mermaid handles spaces in node labels gracefully if they are quoted, but for connections\n",
    "    # the IDs should be simple. Let's make sure our approach is compatible.\n",
    "\n",
    "    # A common Mermaid practice is to have a simple ID for the node and then a label\n",
    "    # like: ID[Label]. If we use the name as ID, it should not have spaces.\n",
    "    # Given the previous step produced names like 'Module 1', we should create a mapping for node IDs.\n",
    "\n",
    "    # Let's refine how we generate the Mermaid lines to ensure valid syntax\n",
    "    # Create a mapping from clean name to a unique, mermaid-safe ID\n",
    "    # This mapping is important to handle cases where names might have characters that Mermaid IDs don't like\n",
    "    node_id_map = {}\n",
    "    counter = 0\n",
    "    for uri_name in all_entity_names.values():\n",
    "        clean_name = uri_name.replace(' ', '_').replace('-', '_').replace(':', '_').replace('.', '_').strip()\n",
    "        if clean_name not in node_id_map.values():\n",
    "            node_id_map[uri_name] = f'N{counter}'\n",
    "            counter += 1\n",
    "\n",
    "    # Create mermaid lines with unique IDs and original names as labels\n",
    "    mermaid_lines = ['graph TD']\n",
    "    for s_name, p_type, o_name in all_mermaid_edges:\n",
    "        source_id = node_id_map.get(s_name, s_name.replace(' ', '_').replace('-', '_').replace(':', '_').replace('.', '_').strip())\n",
    "        target_id = node_id_map.get(o_name, o_name.replace(' ', '_').replace('-', '_').replace(':', '_').replace('.', '_').strip())\n",
    "\n",
    "        # Add node definitions with labels if they contain spaces\n",
    "        if ' ' in s_name:\n",
    "            mermaid_lines.append(f'{source_id}[\\\"{s_name}\\\"]')\n",
    "        if ' ' in o_name:\n",
    "            mermaid_lines.append(f'{target_id}[\\\"{o_name}\\\"]')\n",
    "\n",
    "        mermaid_lines.append(f'{source_id} -- {p_type} --> {target_id}')\n",
    "\n",
    "mermaid_syntax = '\\n'.join(mermaid_lines)\n",
    "\n",
    "# save mermaid file to disk\n",
    "with open(\"lp1.mmd\", \"w\") as mermaid_file:\n",
    "    print(mermaid_syntax, file=mermaid_file)\n",
    "\n",
    "# display the markdown mermaid graph as output of this cell\n",
    "print(mermaid_syntax)"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "#from IPython.display import display, Markdown\n",
    "#Markdown(mermaid_syntax)\n",
    "\n",
    "import base64\n",
    "from IPython.display import display_svg\n",
    "from urllib.request import Request, urlopen\n",
    "\n",
    "def mm(graph):\n",
    "    graphbytes = graph.encode(\"ascii\")\n",
    "    base64_bytes = base64.b64encode(graphbytes)\n",
    "    base64_string = base64_bytes.decode(\"ascii\")\n",
    "    url=\"https://mermaid.ink/svg/\" + base64_string\n",
    "    req=Request(url, headers={'User-Agent': 'IPython/Notebook'})\n",
    "    display_svg(urlopen(req).read().decode(), raw=True)\n",
    "mm(mermaid_syntax)"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": ""
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
